import json
import re
import warnings

from fuzzywuzzy import fuzz, process


try:
    import Levenshtein
except ImportError:
    warnings.warn('Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning')


def preprocess_text(text: str) -> str:
    """
    –§—É–Ω–∫—Ü–∏—è –¥–ª—è –ø—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Ç–µ–∫—Å—Ç–∞: –ø—Ä–∏–≤–µ–¥–µ–Ω–∏–µ –∫ –Ω–∏–∂–Ω–µ–º—É —Ä–µ–≥–∏—Å—Ç—Ä—É –∏ —É–¥–∞–ª–µ–Ω–∏–µ –∑–Ω–∞–∫–æ–≤ –ø—Ä–µ–ø–∏–Ω–∞–Ω–∏—è.
    """
    text = text.lower()
    text = re.sub(r'[^\w\s]', '', text)  # –£–¥–∞–ª–µ–Ω–∏–µ –∑–Ω–∞–∫–æ–≤ –ø—Ä–µ–ø–∏–Ω–∞–Ω–∏—è
    return text

def find_best_match(question: str, all_questions: list, threshold: int = 80) -> str:
    """
    –§—É–Ω–∫—Ü–∏—è –¥–ª—è –Ω–∞—Ö–æ–∂–¥–µ–Ω–∏—è –Ω–∞–∏–±–æ–ª–µ–µ –ø–æ—Ö–æ–∂–µ–≥–æ –≤–æ–ø—Ä–æ—Å–∞ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º fuzzywuzzy.
    """
    preprocessed_question = preprocess_text(question)
    preprocessed_questions = [preprocess_text(q) for q in all_questions]

    closest_matches = process.extract(
        preprocessed_question, preprocessed_questions, limit=1, scorer=fuzz.token_sort_ratio
    )

    if closest_matches and closest_matches[0][1] >= threshold:
        best_match_index = preprocessed_questions.index(closest_matches[0][0])
        return all_questions[best_match_index]
    return None

def keyword_match(question: str, keywords: list) -> bool:
    """
    –§—É–Ω–∫—Ü–∏—è –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ –Ω–∞–ª–∏—á–∏—è –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤ –≤ –≤–æ–ø—Ä–æ—Å–µ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º fuzzywuzzy.
    """
    preprocessed_question = preprocess_text(question)
    for keyword in keywords:
        preprocessed_keyword = preprocess_text(keyword)
        # –ü–æ—Ä–æ–≥ –¥–ª—è —á–∞—Å—Ç–∏—á–Ω–æ–≥–æ —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è
        if fuzz.partial_ratio(preprocessed_question, preprocessed_keyword) > 80:
            return True
    return False


async def answer_for_question(question: str) -> str:
    with open('assets/questions.json', 'r', encoding='utf-8') as file:
        data = json.load(file)

    questions_and_answers = data["questions_and_answers"]
    all_questions = [qa["question"] for qa in questions_and_answers]

    # –ü–æ–∏—Å–∫ –ø–æ –∫–ª—é—á–µ–≤—ã–º —Å–ª–æ–≤–∞–º —Å —á–∞—Å—Ç–∏—á–Ω—ã–º —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ–º
    for qa in questions_and_answers:
        if keyword_match(question, qa.get("keywords", [])):
            return qa["question"], qa["answer"]

    # –ü–æ–∏—Å–∫ –ø–æ —Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–∫–µ –≤–æ–ø—Ä–æ—Å–∞
    closest_question = find_best_match(question, all_questions)
    if closest_question:
        for qa in questions_and_answers:
            if qa["question"] == closest_question:
                return qa["question"], qa["answer"]

    return "–í–æ–ø—Ä–æ—Å –Ω–µ–∫–æ—Ä—Ä–µ–∫—Ç–µ–Ω", "–ò–∑–≤–∏–Ω–∏—Ç–µ, —è –Ω–µ –Ω–∞—à—ë–ª –æ—Ç–≤–µ—Ç–∞ üòî."
